{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc9ee18",
   "metadata": {},
   "source": [
    "# Cuaderno de Reflexión: Optimización en IA\n",
    "\n",
    "**Autor:** Jesús Ariel González Bonilla  \n",
    "**Fecha:** 2025-08-07\n",
    "\n",
    "Este cuaderno sintetiza los **nueve ejercicios** prácticos de optimización desarrollados en clase, aporta claves teóricas y reflexiones críticas, y muestra fragmentos de código mínimos que puedes ejecutar.\n",
    "\n",
    "> Ejecuta las celdas y prueba modificar parámetros para ver su impacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500da707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "from sklearn.datasets import make_regression, load_diabetes, load_breast_cancer, load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.optimize import linprog\n",
    "import pulp\n",
    "import random, math\n",
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba745a9c",
   "metadata": {},
   "source": [
    "## 1. Gradiente Descendente Clásico\n",
    "\n",
    "**Objetivo**: Minimizar $f(x)=x^2$ usando descenso por gradiente.\n",
    "\n",
    "**Fórmula de actualización**:  \n",
    "$$x_{t+1}=x_t-\\eta 2x_t$$\n",
    "\n",
    "**Ideas clave**:\n",
    "- Convergencia lineal para $0<\\eta<1/L$ con $L=2$.  \n",
    "- Demuestra el efecto de la tasa de aprendizaje sobre estabilidad y velocidad.\n",
    "\n",
    "**Reflexión**: Ajustar $\\eta$ balancea rapidez y seguridad; comprender la constante de Lipschitz evita divergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "x, lr, hist = 5.0, 0.4, []\n",
    "for _ in range(30):\n",
    "    x -= lr * 2*x\n",
    "    hist.append(x**2)\n",
    "plt.semilogy(hist); plt.title('GD clásico'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437ceb4",
   "metadata": {},
   "source": [
    "## 2. Gradiente Descendente por Mini-batch\n",
    "\n",
    "**Objetivo**: Comparar GD completo con mini-batch.\n",
    "\n",
    "- El gradiente estimado para un lote $B$ reduce su varianza con $1/|B|$.  \n",
    "- Mini-batch acelera iteraciones pero introduce ruido.\n",
    "\n",
    "**Reflexión**: Encontrar tamaño de lote \"dulce\" depende del hardware y la forma de la función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "X,y = make_regression(n_samples=256,n_features=10,noise=4.0)\n",
    "X,y = map(torch.tensor,[X,y.reshape(-1,1)])\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X.float(),y.float()),batch_size=32,shuffle=True)\n",
    "m=nn.Linear(10,1); opt=torch.optim.SGD(m.parameters(),lr=1e-3); loss=nn.MSELoss()\n",
    "hist=[]\n",
    "for epoch in range(40):\n",
    "    for xb,yb in loader:\n",
    "        opt.zero_grad(); l=loss(m(xb),yb); l.backward(); opt.step()\n",
    "    hist.append(l.item())\n",
    "plt.plot(hist); plt.title('Mini-batch'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35e064",
   "metadata": {},
   "source": [
    "## 3. Mini‑batch con Dataset Diabetes\n",
    "\n",
    "**Objetivo**: Aplicar mini‑batch GD real en un problema de regresión.\n",
    "\n",
    "- Normalizar características mejora isotropía de la pérdida.  \n",
    "- Early stopping evita sobreajuste.\n",
    "\n",
    "**Reflexión**: Combinar teoría de escalamiento con validación cruzada aumenta robustez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c36cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo rápido de early stopping en diabetes\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X,y = load_diabetes(return_X_y=True)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "model = SGDRegressor(alpha=0.0001, learning_rate='invscaling', eta0=0.01)\n",
    "best, patience, wait = 1e9, 5, 0\n",
    "for epoch in range(300):\n",
    "    model.partial_fit(X,y)\n",
    "    mse = mean_squared_error(y, model.predict(X))\n",
    "    if mse < best: best, wait = mse, 0\n",
    "    else: wait+=1\n",
    "    if wait>patience: break\n",
    "print('epochs', epoch, 'best mse', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9e76a",
   "metadata": {},
   "source": [
    "## 4. Gradiente Descendente Estocástico (SGD)\n",
    "\n",
    "**Objetivo**: Observar la trayectoria ruidosa de SGD.\n",
    "\n",
    "- Convergencia esperada $\\mathcal{O}(1/\\sqrt{t})$.  \n",
    "- Momentum suaviza y acelera.\n",
    "\n",
    "**Reflexión**: El barajado de datos y la política de tasa de aprendizaje son tan importantes como la fórmula del gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a32d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, random\n",
    "def f(x): return x**2\n",
    "lr=0.1; x=5; fs=[]\n",
    "for i in range(200):\n",
    "    grad=2*x+np.random.randn()*0.5\n",
    "    x-=lr*grad\n",
    "    fs.append(f(x))\n",
    "plt.plot(fs); plt.title('SGD ruido'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d46de",
   "metadata": {},
   "source": [
    "## 5. Programación Lineal Clásica\n",
    "\n",
    "**Objetivo**: Formular y resolver un problema LP de utilidad.\n",
    "\n",
    "- Comparación de Simplex vs. barrera interior.  \n",
    "- Dualidad para interpretar precios sombra.\n",
    "\n",
    "**Reflexión**: La lectura económica del dual convierte números en decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "c = [-5,-4]         # maximizar -> minimizar negativo\n",
    "A = [[2,1],[1,1]]\n",
    "b = [10,8]\n",
    "res = linprog(c, A_ub=A, b_ub=b, bounds=(0,None))\n",
    "print('Óptimo', -res.fun, 'en x=', res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a961cb",
   "metadata": {},
   "source": [
    "## 6. Programación Lineal en Dataset Cáncer de Mama\n",
    "\n",
    "**Objetivo**: Maximizar margen con restricciones lineales.\n",
    "\n",
    "- Uso de holguras cuando no hay separación perfecta.  \n",
    "- Paralelo con SVM lineal.\n",
    "\n",
    "**Reflexión**: Reformular modelos clásicos en LP ilumina la frontera entre aprendizaje y optimización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc80e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación lineal como LP simplificada con pulp\n",
    "import pulp, numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X,y = data.data[:50,:2], (data.target[:50]*2-1)  # submuestra 2D\n",
    "prob = pulp.LpProblem('margin', pulp.LpMaximize)\n",
    "w1 = pulp.LpVariable('w1'); w2 = pulp.LpVariable('w2'); b = pulp.LpVariable('b'); rho = pulp.LpVariable('rho', lowBound=0)\n",
    "prob += rho\n",
    "for i in range(len(X)):\n",
    "    prob += y[i]*(w1*X[i,0]+w2*X[i,1]+b) >= rho\n",
    "prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "print('Márgen', rho.value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f61e6",
   "metadata": {},
   "source": [
    "## 7. Algoritmos Metaheurísticos\n",
    "\n",
    "**Objetivo**: Explorar Rastrigin con heurísticas.\n",
    "\n",
    "- Recocido simulado vs. algoritmo genético.  \n",
    "- Balance diversificación/intensificación.\n",
    "\n",
    "**Reflexión**: Las heurísticas necesitan métricas claras para no perderse en su propia estocasticidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math\n",
    "def rastrigin(v): return 10*len(v)+sum(x**2-10*math.cos(2*math.pi*x) for x in v)\n",
    "best=[random.uniform(-5,5) for _ in range(2)]\n",
    "T=1.0\n",
    "for k in range(5000):\n",
    "    cand=[x+random.gauss(0,0.3) for x in best]\n",
    "    if random.random()<math.exp((rastrigin(best)-rastrigin(cand))/T):\n",
    "        best=cand\n",
    "    T*=0.999\n",
    "print('Best', rastrigin(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f682a9",
   "metadata": {},
   "source": [
    "## 8. Optimización de Hiperparámetros\n",
    "\n",
    "**Objetivo**: Comparar Grid Search y Random Search.\n",
    "\n",
    "- Random Search cubre mejor espacios de alta dimensión con pocas evaluaciones.  \n",
    "- Métricas múltiples (F1, AUC) guían la selección.\n",
    "\n",
    "**Reflexión**: El costo de exploración debe sopesarse contra el rendimiento marginal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "X,y = load_wine(return_X_y=True)\n",
    "param_space={'n_estimators':[50,100,200],'max_depth':[None,3,5,7]}\n",
    "rs=RandomizedSearchCV(RandomForestClassifier(),param_space,n_iter=5,cv=3,scoring='accuracy')\n",
    "rs.fit(X,y)\n",
    "print('Mejor score', rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68babe6",
   "metadata": {},
   "source": [
    "## 9. Optimización Bayesiana\n",
    "\n",
    "**Objetivo**: Minimizar caja negra con procesos gaussianos y Expected Improvement.\n",
    "\n",
    "- Surrogate model equilibra exploración y explotación.  \n",
    "- Kernel y parámetro $\\xi$ controlan agresividad.\n",
    "\n",
    "**Reflexión**: Pensar en términos de *valor de información* conduce a estrategias de búsqueda más inteligentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "def f(x):\n",
    "    import math\n",
    "    return (x[0]-2)**2+math.sin(5*x[0])\n",
    "res = gp_minimize(f, [(-5.0,5.0)], n_calls=20, random_state=0)\n",
    "print('x*', res.x[0], 'f*', res.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b41e7",
   "metadata": {},
   "source": [
    "## Conclusiones Finales\n",
    "\n",
    "- Las técnicas de **descenso por gradiente** son la espina dorsal del aprendizaje profundo; su comportamiento depende fuertemente de la tasa de aprendizaje y del tamaño de lote.\n",
    "- **Programación lineal** sigue vigente: ofrece interpretabilidad y garantías cuando el modelo es lineal.\n",
    "- **Metaheurísticas** proporcionan alternativas en espacios no convexos, pero requieren criterios de parada y análisis estadístico.\n",
    "- La **optimización de hiperparámetros** combina exploración y explotación; métodos bayesianos ahorran evaluaciones cuando los modelos son costosos.\n",
    "- Cualquier experimento de optimización debe acompañarse de **visualización, validación cruzada** y un registro reproducible de configuraciones."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
